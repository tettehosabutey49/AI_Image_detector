{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801a803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67a3523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.image = self._load_image()\n",
    "    \n",
    "    def _load_image(self):\n",
    "        \"\"\"Load image using OpenCV with error handling.\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(self.image_path)\n",
    "            if image is None:\n",
    "                raise FileNotFoundError\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess(self, target_size=(224, 224)):\n",
    "        \"\"\"Resize and normalize image for ML model.\"\"\"\n",
    "        resized = cv2.resize(self.image, target_size)\n",
    "        normalized = resized / 255.0  # Scale pixel values\n",
    "        return np.expand_dims(normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "# Test it\n",
    "processor = ImageProcessor(\"C:/Users/tette/OneDrive/Documents/AI_Image_Detection/image2.jpg\")\n",
    "processed_img = processor.preprocess()\n",
    "print(processed_img.shape)  # Should print (1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d30526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tette\\OneDrive\\Documents\\AI_Image_Detection\\ai_image_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tette\\OneDrive\\Documents\\AI_Image_Detection\\ai_image_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class AIDetector:\n",
    "    def __init__(self):\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    def predict(self, input_tensor):\n",
    "        \"\"\"Convert NumPy array to tensor and predict.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            tensor = torch.from_numpy(input_tensor).float()\n",
    "            tensor = tensor.permute(0, 3, 1, 2)  # Change to (batch, channels, H, W)\n",
    "            output = self.model(tensor)\n",
    "        return \"AI\" if output.argmax().item() == 1 else \"Real\"\n",
    "\n",
    "# Test\n",
    "detector = AIDetector()\n",
    "result = detector.predict(processed_img)\n",
    "print(f\"Prediction: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db511f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d23146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2ca37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a03800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcc903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fe8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a318d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50105a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_image_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
