{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801a803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image maniupulation\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "##pretrained model\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16c9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ai_artifacts(image):\n",
    "    ##Check for unnatural edges/smoothness (common in AI images).\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)      #convert coloured image to black and white\n",
    "    edges = cv2.Canny(gray, 100, 200)                   #detect sharp intensity changes\n",
    "    edge_score = np.mean(edges)                          # find average edge strength\n",
    "    return edge_score < 30                               # a Lower edge_score = smoother (likely AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a3523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path         #initialize with path to the image\n",
    "        self.image = self._load_image()     # Load image immediately on initialization\n",
    "    \n",
    "    #loading the image\n",
    "    def _load_image(self):\n",
    "        try:\n",
    "            image = cv2.imread(self.image_path)   #laod the image using opencv\n",
    "            if image is None:\n",
    "                raise FileNotFoundError\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "     #preprocess the image for the model\n",
    "    def preprocess(self, target_size=(224, 224)):\n",
    "        \n",
    "        resized = cv2.resize(self.image, target_size)     #resize image(into CNN format)      \n",
    "        normalized = resized / 255.0                      # Scale pixel values(to values b/n 0-1)\n",
    "        return np.expand_dims(normalized, axis=0)        # Add batch dimension (models expect input in batches) batch_shape: ( (1, height, width, channels))\n",
    "\n",
    "\n",
    "processor = ImageProcessor(\"C:/Users/tette/OneDrive/Documents/AI_Image_Detection/image2.jpg\")\n",
    "processed_img = processor.preprocess()\n",
    "print(processed_img.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDetector:\n",
    "    def __init__(self):\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, input_tensor):\n",
    "        \"\"\"Use feature-based approach instead of classification.\"\"\"\n",
    "        with torch.no_grad():               \n",
    "            tensor = torch.from_numpy(input_tensor).float()\n",
    "            tensor = tensor.permute(0, 3, 1, 2)\n",
    "            \n",
    "            # Get features from the model (before final classification)\n",
    "            features = self.model.avgpool(self.model.layer4(\n",
    "                self.model.layer3(self.model.layer2(self.model.layer1(\n",
    "                    self.model.maxpool(self.model.relu(self.model.bn1(self.model.conv1(tensor))))\n",
    "                )))\n",
    "            )).flatten()\n",
    "            \n",
    "            # Use feature variance as AI indicator\n",
    "            # AI images often have more uniform features\n",
    "            feature_variance = torch.var(features).item()\n",
    "            \n",
    "            return \"AI\" if feature_variance < 0.5 else \"Real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d23146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDetector:\n",
    "    #Detect AI images using deep features\n",
    "    \n",
    "    def __init__(self):\n",
    "        #Initialize with ResNet18 (pretrained on ImageNet).\n",
    "        # Load model with pretrained weights\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Set to evaluation mode (disables dropout/batchnorm updates)\n",
    "        self.model.eval()  \n",
    "    \n",
    "    def predict(self, input_tensor):\n",
    "        ##Predict using feature variance analysis.\n",
    "        \n",
    "        with torch.no_grad():       # dont do gradient calculation(no training)\n",
    "            # Convert arrays to PyTorch tensor and reshape \n",
    "            tensor = torch.from_numpy(input_tensor).float()\n",
    "            tensor = tensor.permute(0, 3, 1, 2)  # Channels-first\n",
    "            \n",
    "            # Extract features from intermediate layers\n",
    "            x = self.model.conv1(tensor)\n",
    "            x = self.model.bn1(x)\n",
    "            x = self.model.relu(x)\n",
    "            x = self.model.maxpool(x)\n",
    "            \n",
    "            x = self.model.layer1(x)\n",
    "            x = self.model.layer2(x)\n",
    "            x = self.model.layer3(x)\n",
    "            x = self.model.layer4(x)\n",
    "            \n",
    "            # Get final features before classification\n",
    "            features = self.model.avgpool(x).flatten()\n",
    "            \n",
    "            #Calculate feature variance\n",
    "            feature_variance = torch.var(features).item()\n",
    "            \n",
    "            #Variance less than 0.5 implies its AI generated \n",
    "            return \"AI\" if feature_variance < 0.5 else \"Real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2ca37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a03800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcc903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fe8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a318d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50105a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_image_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
